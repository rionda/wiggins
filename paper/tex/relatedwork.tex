\section{Related Work}\label{sec:related_work}
The problem we focus on is novel and generalizes and complements other problems
studied in the literature.

The  ``Battle of Water Sensor Network'' challenge~\citep{BWSN2008} motivated a
number of works on \emph{outbreak detection}: the goal is to optimally place
static or moving sensors in water networks to detect
contamination~\citep{Leskovec2007,Krause2008,Hart2010}. The optimization can be
done w.r.t.~a number of objectives, such as maximizing the probability of
detection, minimizing the detection time, or minimizing the size of the
subnetwork affected by the phenomena~\citep{Leskovec2007}. A related
work~\citep{AgumbeSuresh2012} considered sensors that are sent along fixed paths
in the network with the goal of gathering sufficient information to locate
possible contaminations. Early detection of contagious outbreaks by monitoring
the neighborhood (friends) of a randomly chosen node (individual) was studied
by~\citet{Christakis2010}.  \citet{Krause2009} present efficient schedules for
minimizing energy consumption in battery operated sensors, while other works
analyzed distributed solutions with limited communication capacities and
costs~\citep{Krause2011Kleinberg,Golovin2010,Krause2011}. % spacesaver
%Another objective in the Sensor Placement problem is to {\bf predict} the phenomena at locations without sensors (e.g., road speeds on highways).  studies this problem where there is restriction on the battery life of the sensors, and thus, the sensors need to be placed and \emph{scheduled} such that at each time just some of the sensors are \emph{active}. Also, \cite{Golovin2010} studies the same problem and provides a distributed solution where the sensors are not connected to a centralized optimizer and they activate themselves using local information. \cite{Krause2011} presents an algorithm in which sensors have to communicate through
%lossy channels in environmental monitoring, and \cite{Krause2011Kleinberg} brings the communication cost into account.
In contrast, our work is geared to detection in huge but virtual networks such
as the Web or social networks embedded in the Internet, where it is possible to
``sense'' or probe (almost) any node at approximately the same cost. Still only
a restricted number of nodes can be probed at each steps but the optimization of
the probing sequence is over a much larger domain, and the goal is to identify
the outbreaks (items) regardless of their size and solely by considering their
interest value.

%An interesting related research direction aims at \emph{controlling} or
%\emph{stopping} contagions in the networks by changing the topology of the
%network (e.g, by protecting or blocking the edges and/or
%nodes)~\cite{Aspnes2006,Kimura2008Minimizing,Kimura2008,Kimura2009,Li2011,He2011,Kuhlman2013}. %
%In our model, though, probing the nodes is the only action we can take.}
%%%%%%%%%%%%%%
%\emph{Anomaly Detection} instead requires to find the events (usually
%structural) that deviate from \emph{normal}
%patterns~\cite{Noble2003,Sun2007,Eberle2007,Papadimitriou2010,Akoglu2010,Bogdanov2013}.
%%%%%%%%%%%%%%%%

Our methods complement the work on \emph{Emerging Topic Detection} where the
goal is to identify emergent topics in a social network, assuming full access to
the stream of all postings. Providers, such as Twitter or Facebook, have an
immediate access to all tweets or postings as they are submitted to their
server~\cite{Cataldi2010,Mathioudakis2010}. Outside observers need an efficient
mechanism to monitor changes, such as the methods developed in this work.

\emph{Web-crawling} is another research area that study how to obtain the
most recent snapshots of the web. However, it differs from our model in two key
points: our model allows items to propagate their copies, and they will be
caught if any of their copies is discovered (where snapshots of a webpage belong
to that page only), and all the generated items should be discovered (and not
just the recent ones)~\cite{dasgupta2007discoverability,wolf2002optimal}.

\ahmad{The \emph{News and Feed Aggregation} problem is a very well-studied topic, whose goal is to capture the updates of news websites (e.g. by RSS feeds)~\cite{survey-oita2011deriving,onlineRef-horincar2014online,adaptive-bright2006adaptive}. Beside having different objectives, our model differs mainly in the assumption that items may get copied/propagated in the network and we do not need to catch all the copies, where in Feed Aggregation news (items) from different}
%\ahmad{
%The \emph{News and Feed Aggregation} problem is a very well-studied topic, in which the general goal is to obtain the updates of news websites (e.g. by RSS feeds). Among many introduced objectives~\cite{survey-oita2011deriving,onlineRef-horincar2014online,adaptive-bright2006adaptive} in studying this problem, the most similar one to our cost function is the \emph{delay} function presented by~\cite{fast-sia2007efficient}.  In~\cite{fast-sia2007efficient} it is assumed that the rates of the news publication does not change, where in our setting these rates may change and our algorithm ({\ada}) can adapt itself to the new setting. Also, we assume at any given time the number of probes is fixed (or bounded) regarding the limited computational power for simultaneous probes, but \cite{fast-sia2007efficient} uses a relaxed  assumption by fixing the number of probes over a \emph{time window} of a fixed length which may result in high number of probes at a single time step. Finally, \cite{fast-sia2007efficient} introduces a deterministic algorithm in which the number of probes to each feed is obtained by applying the Lagrange multipliers method (very similar result to Theorem~\ref{thm:randomized_schedule}), but they loose the guarantee on optimality of their solution, by rounding the estimated number of probes to integers. In contrast, our solution provides  theoretical guarantee on optimality of our output schedule. }


% Finally, there are many work on Influence Maximization  and the social network Centrality, but as explained in previous section, they are ``orthogonal'' to  1-PHSP. To see the work on Influence Maximization and Betweenness centrality you can refer to \cite{Kempe2007,Borgs} and \cite{Yoshida}, and their related work.

% Finally, the well-studied problem of \emph{Influence Maximization} problem aimed at optimizing the location of nodes to seed new items, in order to obtain maximum spread of the items~\cite{Kempe2003,Kempe2005,Kempe2007,Chen2009,Chen2010,Goyal2011,Seeman13}.




% % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % Section: Related   work % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % %
% \section{Related work}\label{sec:related_work}
% There has been an extensive work on \emph{outbreak detecdion} in physical domains, in particular the "Battle of Water Sensor Network" challenge~\cite{BWSN2008}  for optimal placement of static sensors in water networks to detect contamination~\cite{Leskovec2007,Krause2008,Hart2010}.
% The optimization is done with respect to different objectives, such as maximizing the probability of detection, minimizing the detection time, or minimizing the size of the subnetwork affected by the phenomena~\cite{Leskovec2007}. A related work~\cite{AgumbeSuresh2012} considered  sensors that are sent along fixed paths in the network with the goal of gathering sufficient information to locate possible contaminations. Early detection of contagious outbreaks
% by monitoring the neighborhood (friends) of a randomly chosen node (individual) was studied in~\cite{Christakis2010}. Efficient scheduling for minimizing energy consumption in battery operated sensors were studied in~\cite{Krause2009}, and distributed solutions with limited communication capacities and costs were studied in~\cite{Krause2011Kleinberg, Golovin2010, Krause2011}.
%
% %Another objective in the Sensor Placement problem is to {\bf predict} the phenomena at locations without sensors (e.g., road speeds on highways).  studies this problem where there is restriction on the battery life of the sensors, and thus, the sensors need to be placed and \emph{scheduled} such that at each time just some of the sensors are \emph{active}. Also, \cite{Golovin2010} studies the same problem and provides a distributed solution where the sensors are not connected to a centralized optimizer and they activate themselves using local information. \cite{Krause2011} presents an algorithm in which sensors have to communicate through
% %lossy channels in environmental monitoring, and \cite{Krause2011Kleinberg} brings the communication cost into account.
% %
% In contrast to these works our work is geared to detection in virtual networks such as the Web or social networks embedded in the Internet, where a monitor can reach (almost) any node at about the same cost. The monitor is still restricted to probing a small number of nodes per step, but the optimization of the probing sequence is over a larger and more complex domain.
%
% \ahmad{Another trend of studies, aim to \emph{controlling} or \emph{stopping} contagions in the networks by changing the topology of the network (e.g, by protecting or blocking the edges and/or nodes)~\cite{Aspnes2006,Kimura2008Minimizing,Kimura2008,Kimura2009,Li2011,He2011,Kuhlman2013}. In our model, though, probing the nodes is the only action we can take.}
%
% Our methods complement the work on \emph{Emerging Topic Detection} where the goal is to identify emergent topics in a social network, assuming full access to the stream all posting. Providers, such as Twitter of Facebook, have an immediate access to all tweets or postings as they are submitted to their server~\cite{Cataldi2010,Mathioudakis2010}. Outside observers need an efficient mechanism to monitor changes.
%
% %%%%%%%%%%%%%%
% \ahmad{
% There is a rich work in the area of \emph{Anomaly Detection} whose goal is to find the events (usually structural) that deviate from a \emph{normal} pattern, e.g see \cite{Noble2003,Sun2007,Eberle2007,Papadimitriou2010,Akoglu2010,Bogdanov2013}. In our work we assume a fixed set of parameters, and rather focusing on the pattern of the events (e.g., pattern of the subnetwork that an item has reached) we are interested in catching (all) the items.
% }
% %%%%%%%%%%%%%%%%
%
% Finally, the well-studied problem of \emph{Influence Maximization} problem aimed at optimizing the location of nodes that generated new items to obtain maximum spread of the items~\cite{Kempe2003,Kempe2005,Kempe2007,Chen2009,Chen2010,Goyal2011,Seeman13}. \ahmad{Note that the goal in Influence Maximization problem is to spread the items to the largest \emph{size}, while reversely, we aim to detect the items in shortest \emph{time}.}
%
% % \ahmad{ \st{measuring the influence of people }~\cite{Weng2010,Cha2010}}
%
%
%
