\section{Problem Definition}\label{sec:prelims}
In this section we formally introduce the problem and define our goal.

Let $G=(V,E)$ be a graph with $|V|=n$ nodes. W.l.o.g. we let $V=[n]$. Let
$\family\subseteq 2^V$ be a collection of subsets of $V$, i.e., a collection of
sets of nodes. Let $\pi$ be a function from $\family$ to $[0,1]$ (not
necessarily a probability distribution). We model the generation and diffusion
of  information in the network by defining a \emph{generating
process} $\sys=(\family,\pi)$.  $\sys$ is a infinite discrete-time process
which, at each time step $t$, generates a collection of sets $\Sample_t\subseteq\family$ such
that each set $S\in\family$ is included in $\Sample_t$ with probability $\pi(S)$,
independent of $t$ and of other sets generated at time $t'\leq t$.
For any $t$ and any $S\in\Sample_t$, the ordered pair $(t,S)$ represents an
\emph{item} - a piece of information that was generated at time
$t$ and reached \emph{instantaneously} the nodes in $S$. We choose to model the
diffusion process as instantaneous because this abstraction accurately models the view of an outside
\emph{resource-limited observer} that does not have the resources to monitor simultaneously all
the nodes in the network at the fine time granularity needed to observe the
different stages of the diffusion process.

\para{Probing and schedule} The observer can only monitor the network by
\emph{probing} nodes. Formally, by \emph{probing a node $v\in V$ at time $t$},
we mean obtaining the set $I(t,v)$ of items $(t',S)$ such
that $t'\le t$ and $v\in S$:\footnote{The set $S$ appears in the notation for an
	item only for clarity of presentation: we are \emph{not} assuming that when
we probe a node and find an item $(t,S)$ we obtain information about $S$.}
\[
	I(t,v)\defeq\{(t',S) ~:~ t'\le t, S\in\Sample_{t'}, v\in S\}\enspace.
\]
Let $U_t$ be the union of the sets $\Sample_{t'}$ generated by $\sys$
at any time $t'\le t$, and so $I(t,v)\subseteq U_t$.

%We assume that
%probing a node $v$ at time $t$ is not a computationally expensive operation and
%gives immediate access to $I(t,v)$. This is a realistic assumption:
%for example, accessing the profile of a user in a social network gives access to
%the list of items that reached that user, and is not computationally expensive.
%
We model the \emph{resource limitedness of the observer} through a constant,
user-specified, parameter $c\in\mathbb{N}$, representing the maximum number of
nodes that can be probed at any time, where probing a node $v$ returns the value $I(t,v)$.

The observer chooses the $c$ nodes to probe by following a schedule. In this work
we focus on \emph{memoryless} schedules, i.e., the choice of nodes to probe at
time $t$ is independent from the choice of nodes probed at any time $t'<t$.
More precisely, a \emph{probing $c$-schedule} $\sched$ is a probability
distribution on $V$. At each time $t$, the observer chooses a set $P_t$ of $c$
nodes to probe, such that $P_t$ is obtained through \emph{random sampling of $V$
without replacement according to $\sched$}, independently from $P_{t'}$ from
$t'< t$. Memoryless schedules are simple, easy to store, and fast to implement. 
%We postpone the study of adaptive or sequential schedules to future work.

\para{Caught items, uncaught items, and novelty}
We say that an item $(t',S)$ is \emph{caught at time $t\ge t'$} iff
\begin{enumerate*}
	\item a node $v\in S$ is probed at time $t$; and
	\item no node in $S$ was probed in the interval $[t',t-1]$.
\end{enumerate*}

Let $C_t$ be the set of items caught by the observer at any time $t'\le t$. We
have $C_t\subseteq U_t$. Let $N_t= U_t\setminus C_t$ be the \emph{set of
uncaught items at time $t$}, i.e., items that were generated at any time
$t'\le t$ and have not been caught yet at time $t$. For any item $(t',S)\in
N_t$, we define the \emph{$\theta$-novelty of $(t',S)$ at time $t$} as
\[
	\fresh_\theta(t,t',S)\defeq\theta^{t-t'},
\]
where $\theta\in(0,1)$ is a user-specified parameter modeling how fast the
value of an item decreases with time if uncaught. Intuitively, pieces of
information (e.g., rumors) have high value if caught almost as soon as they have
appeared in the network, but their value decreases fast (i.e., exponentially) as
more time passes before being caught, to the point of having no value in the
limit.

\para{Load of the system and cost of a schedule} The set $N_t$ of uncaught items
at time $t$ imposes a \emph{$\theta$-load, $L_\theta(t)$, on the graph at time
$t$}, defined as the sum of the $\theta$-novelty at time $t$ of the items in
$N_t$:
\[
	L_\theta(t)\defeq\sum_{(t',S)\in N_t} \fresh_\theta(t,t',S)\enspace.
\]
The quantity $L_\theta(t)$ is a random variable, depending both on $\sys$ and on
the probing schedule $\sched$, and as such it has an expectation
$\expect[L_\theta(t)]$ w.r.t.~all the randomness in the system. The
\emph{$\theta$-cost of a schedule $\sched$} is defined as the limit, for
$t\rightarrow\infty$, of the average expected load of the system:
\begin{align*}
	\cost_\theta(\sched)&\defeq\lim_{t\rightarrow\infty}\frac{1}{t}\sum_{t'\le
	t}\expect[L_\theta(t)]\\
	&=\lim_{t\rightarrow\infty}\frac{1}{t}\sum_{t'\le
	t}\expect\left[\sum_{(t'',S)\in N_{t'}}\fresh_\theta(t',t'',S)\right]\enspace.
\end{align*}
Intuitively, the load at each time indicates the amount of novelty we did not
catch at that time, and the cost function measures the average of such loss over
time. The limit above always exists (Lemma~\ref{lem:explicit}).

We now have all the necessary ingredients to formally define the problem of
interest in this work.

\para{Problem definition} Let $G=(V,E)$ be a graph and $\sys=(\family,\pi)$ be a
generating process on $G$. Let $c\in\mathbb{N}$ and
$\theta\in(0,1)$. The \emph{$(\theta,c)$-Optimal Probing Schedule Problem}
($(\theta,c)$-OPSP) requires to find the \emph{optimal $c$-schedule} $\sched^*$,
i.e., the schedule with \emph{minimum} $\theta$-cost over the set $\mathsf{S}_c$
of $c$-schedules:
\[
	\sched^*=\arg\min_{\sched} \{\cost_\theta(\sched), \sched\in\mathsf{S}_c\}\enspace.
\]
Thus, the goal is to design a $c$-schedule that discovers the maximum number of items weighted by their
novelty value (which correspond to those generated most recently).
The parameter $\theta$ controls how fast the novelty of an item decays, and influences the choices of a schedule.
%, i.e.,
%how fast they loose value for the agent.
When $\theta$ is closed to $0$, items are relevant only for a few steps and the schedule
must focus on the most recently generated items, catching them as soon as they are generated (or at most shortly
thereafter). At the other extreme ($\theta\approx 1$), an optimal schedule
must maximizes the total number of discovered items, as their novelty decays very
slowly.
%In other words, the optimal schedule is such that elements of $U$ more
%likely to receive ``novel'' items have higher probability of being probed.

Viewing the items as ``information'' disseminated in the network,
an ideal schedule assigns higher probing probability  to nodes
that act as \emph{ information hubs}, i.e., nodes that receive a large number of
items. Thus, an optimal schedule $\sched^*$, identifies
information hubs among the nodes. This task (finding information hubs) can be
seen as the complement of the \emph{influence maximization
problem}~\citep{Kempe2003,Kempe2005}. In the influence maximization problem we
look for a set of nodes that \emph{generate} information that reach most nodes.
In the information hubs problem, we are interested in a set of nodes that
\emph{receive} the most of information, thus the most informative nodes for an
observer.

In the following sections, we may drop the specification of the parameters
from $\theta$-novelty, $\theta$-cost, $\theta$-load, and $c$-schedule, and
from their respective notation, as the parameters will be clear from the
context.

% Commented by Matteo on 6/30
%In a social network, news and pictures are shared and re-shared over time, and
%each such shared ``item'' reaches a certain set of users. A resource-limited
%agent is interested in knowing what items get shared on the network. Also, the
%agent would like to know as soon as possible that an item has been shared,
%because the value of this piece of information decreases over time. Being
%resource-limited, the only way that the agent can observe (catch) the sharing of
%items is to probe some nodes (i.e., users) of the social network, for example by
%accessing their profile and getting a list of the items that they received from
%other users or that they shared. Therefore, the agent needs a probing schedule
%that allows her to catch as many items as possible while minimizing the time
%between the sharing of an item and its being caught. Equivalently, the schedule
%must be such that the ``value'' of the information that is not caught by the
%agent is minimized. Intuitively, the schedule must be such that nodes that
%receive a high number of items shortly after they have been generated should
%have a higher probability of being probed. These nodes act, in some sense, as
%``information hubs''. As such, identifying them can be seen as the complement of
%the \emph{influence maximization problem}~\citep{Kempe2003,Kempe2005}. In the
%influence maximization problem we look for a set of nodes that \emph{generate}
%information that reach most nodes. In the information hubs problem we are
%interested in a set of nodes that \emph{receive} the most of information, thus
%the most informative nodes for an observer.
